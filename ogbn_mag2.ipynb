{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import torch_geometric\n",
    "import torch\n",
    "from torch_geometric.datasets import OGB_MAG\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.loader import NeighborLoader"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "print(torch.__version__)\n",
    "print(torch_geometric.__version__)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1.8.2\n",
      "2.0.1\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "dataset = OGB_MAG(root='./data', preprocess='metapath2vec', transform=T.ToUndirected(merge=True))\n",
    "data = dataset[0]\n",
    "print(data)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "HeteroData(\n",
      "  \u001b[1mpaper\u001b[0m={\n",
      "    x=[736389, 128],\n",
      "    y=[736389],\n",
      "    train_mask=[736389],\n",
      "    val_mask=[736389],\n",
      "    test_mask=[736389]\n",
      "  },\n",
      "  \u001b[1mauthor\u001b[0m={ x=[1134649, 128] },\n",
      "  \u001b[1minstitution\u001b[0m={ x=[8740, 128] },\n",
      "  \u001b[1mfield_of_study\u001b[0m={ x=[59965, 128] },\n",
      "  \u001b[1m(author, affiliated_with, institution)\u001b[0m={ edge_index=[2, 1043998] },\n",
      "  \u001b[1m(author, writes, paper)\u001b[0m={ edge_index=[2, 7145660] },\n",
      "  \u001b[1m(paper, cites, paper)\u001b[0m={ edge_index=[2, 10792672] },\n",
      "  \u001b[1m(paper, has_topic, field_of_study)\u001b[0m={ edge_index=[2, 7505078] },\n",
      "  \u001b[1m(institution, rev_affiliated_with, author)\u001b[0m={ edge_index=[2, 1043998] },\n",
      "  \u001b[1m(paper, rev_writes, author)\u001b[0m={ edge_index=[2, 7145660] },\n",
      "  \u001b[1m(field_of_study, rev_has_topic, paper)\u001b[0m={ edge_index=[2, 7505078] }\n",
      ")\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "data.metadata()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(['paper', 'author', 'institution', 'field_of_study'],\n",
       " [('author', 'affiliated_with', 'institution'),\n",
       "  ('author', 'writes', 'paper'),\n",
       "  ('paper', 'cites', 'paper'),\n",
       "  ('paper', 'has_topic', 'field_of_study'),\n",
       "  ('institution', 'rev_affiliated_with', 'author'),\n",
       "  ('paper', 'rev_writes', 'author'),\n",
       "  ('field_of_study', 'rev_has_topic', 'paper')])"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "train_loader = NeighborLoader(data, num_neighbors=[15, 15], batch_size=128, input_nodes=('paper', data['paper'].train_mask), shuffle=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "print(train_loader)\n",
    "batch = next(iter(train_loader))\n",
    "print(batch)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "NeighborLoader()\n",
      "HeteroData(\n",
      "  \u001b[1mpaper\u001b[0m={\n",
      "    x=[23023, 128],\n",
      "    y=[23023],\n",
      "    train_mask=[23023],\n",
      "    val_mask=[23023],\n",
      "    test_mask=[23023],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1mauthor\u001b[0m={ x=[4438, 128] },\n",
      "  \u001b[1minstitution\u001b[0m={ x=[322, 128] },\n",
      "  \u001b[1mfield_of_study\u001b[0m={ x=[2977, 128] },\n",
      "  \u001b[1m(author, affiliated_with, institution)\u001b[0m={ edge_index=[2, 0] },\n",
      "  \u001b[1m(author, writes, paper)\u001b[0m={ edge_index=[2, 5669] },\n",
      "  \u001b[1m(paper, cites, paper)\u001b[0m={ edge_index=[2, 13465] },\n",
      "  \u001b[1m(paper, has_topic, field_of_study)\u001b[0m={ edge_index=[2, 11363] },\n",
      "  \u001b[1m(institution, rev_affiliated_with, author)\u001b[0m={ edge_index=[2, 735] },\n",
      "  \u001b[1m(paper, rev_writes, author)\u001b[0m={ edge_index=[2, 4610] },\n",
      "  \u001b[1m(field_of_study, rev_has_topic, paper)\u001b[0m={ edge_index=[2, 11943] }\n",
      ")\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "from torch_geometric.nn import TransformerConv, GCNConv, GATConv, SAGEConv, to_hetero, Linear, HeteroConv\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "class Net1(torch.nn.Module):\n",
    "    def __init__(self, hidden_dim, num_classes, num_layers=2) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_classes = num_classes\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.convs = nn.ModuleList()\n",
    "        self.lins = nn.ModuleList()\n",
    "        self.bns = nn.ModuleList()\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            self.convs.append(GATConv((-1, -1), hidden_dim))\n",
    "            self.lins.append(Linear(-1, hidden_dim))\n",
    "            self.bns.append(nn.BatchNorm1d(hidden_dim))\n",
    "\n",
    "        # self.dropout = torch.nn.Dropout()\n",
    "        self.fc_out = Linear(-1, num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.convs[i](x, edge_index) + self.lins[i](x)\n",
    "            x = self.bns[i](x)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.fc_out(x)\n",
    "        return x"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "class Net2(nn.Module):\n",
    "    def __init__(self, hidden_dim, num_classes, num_layers=2):\n",
    "        super().__init__()\n",
    "\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_classes = num_classes\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.convs = nn.ModuleList()\n",
    "        self.bns = nn.ModuleList()\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            self.convs.append(HeteroConv({\n",
    "                ('author', 'affiliated_with', 'institution'): SAGEConv((-1, -1), hidden_dim),\n",
    "                ('author', 'writes', 'paper'): GATConv((-1, -1), hidden_dim),\n",
    "                ('paper', 'cites', 'paper'): TransformerConv((-1, -1), hidden_dim),\n",
    "                ('paper', 'has_topic', 'field_of_study'): GATConv((-1, -1), hidden_dim),\n",
    "                ('institution', 'rev_affiliated_with', 'author'): SAGEConv((-1, -1), hidden_dim),\n",
    "                ('paper', 'rev_writes', 'author'): SAGEConv((-1, -1), hidden_dim),\n",
    "                ('field_of_study', 'rev_has_topic', 'paper'): SAGEConv((-1, -1), hidden_dim)\n",
    "            }, aggr='sum'))\n",
    "            # self.bns.append(nn.)\n",
    "\n",
    "        self.fc_out = Linear(-1, num_classes)\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict):\n",
    "        for i in range(self.num_layers):\n",
    "            x_dict = self.convs[i](x_dict, edge_index_dict)\n",
    "            x_dict = {key: nn.BatchNorm1d(x.shape[1])(x) for key, x in x_dict.items()}    \n",
    "            x_dict = {key: F.relu(x) for key, x in x_dict.items()}\n",
    "            x_dict = {key: F.dropout(x, p=0.5, training=self.training) for key, x in x_dict.items()}    \n",
    "        \n",
    "        return self.fc_out(x_dict['paper'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "model = Net1(hidden_dim=64, num_classes=dataset.num_classes, num_layers=2)\n",
    "model = to_hetero(model, data.metadata(), aggr='sum').to(device)\n",
    "print(model)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cuda\n",
      "GraphModule(\n",
      "  (convs): ModuleList(\n",
      "    (0): ModuleDict(\n",
      "      (author__affiliated_with__institution): GATConv((-1, -1), 64, heads=1)\n",
      "      (author__writes__paper): GATConv((-1, -1), 64, heads=1)\n",
      "      (paper__cites__paper): GATConv((-1, -1), 64, heads=1)\n",
      "      (paper__has_topic__field_of_study): GATConv((-1, -1), 64, heads=1)\n",
      "      (institution__rev_affiliated_with__author): GATConv((-1, -1), 64, heads=1)\n",
      "      (paper__rev_writes__author): GATConv((-1, -1), 64, heads=1)\n",
      "      (field_of_study__rev_has_topic__paper): GATConv((-1, -1), 64, heads=1)\n",
      "    )\n",
      "    (1): ModuleDict(\n",
      "      (author__affiliated_with__institution): GATConv((-1, -1), 64, heads=1)\n",
      "      (author__writes__paper): GATConv((-1, -1), 64, heads=1)\n",
      "      (paper__cites__paper): GATConv((-1, -1), 64, heads=1)\n",
      "      (paper__has_topic__field_of_study): GATConv((-1, -1), 64, heads=1)\n",
      "      (institution__rev_affiliated_with__author): GATConv((-1, -1), 64, heads=1)\n",
      "      (paper__rev_writes__author): GATConv((-1, -1), 64, heads=1)\n",
      "      (field_of_study__rev_has_topic__paper): GATConv((-1, -1), 64, heads=1)\n",
      "    )\n",
      "  )\n",
      "  (lins): ModuleList(\n",
      "    (0): ModuleDict(\n",
      "      (paper): Linear(-1, 64, bias=True)\n",
      "      (author): Linear(-1, 64, bias=True)\n",
      "      (institution): Linear(-1, 64, bias=True)\n",
      "      (field_of_study): Linear(-1, 64, bias=True)\n",
      "    )\n",
      "    (1): ModuleDict(\n",
      "      (paper): Linear(-1, 64, bias=True)\n",
      "      (author): Linear(-1, 64, bias=True)\n",
      "      (institution): Linear(-1, 64, bias=True)\n",
      "      (field_of_study): Linear(-1, 64, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (bns): ModuleList(\n",
      "    (0): ModuleDict(\n",
      "      (paper): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (author): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (institution): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (field_of_study): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): ModuleDict(\n",
      "      (paper): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (author): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (institution): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (field_of_study): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (fc_out): ModuleDict(\n",
      "    (paper): Linear(-1, 349, bias=True)\n",
      "    (author): Linear(-1, 349, bias=True)\n",
      "    (institution): Linear(-1, 349, bias=True)\n",
      "    (field_of_study): Linear(-1, 349, bias=True)\n",
      "  )\n",
      ")\n",
      "import torch\n",
      "def forward(self, x, edge_index):\n",
      "    x__paper = x.get('paper')\n",
      "    x__author = x.get('author')\n",
      "    x__institution = x.get('institution')\n",
      "    x__field_of_study = x.get('field_of_study');  x = None\n",
      "    edge_index__author__affiliated_with__institution = edge_index.get(('author', 'affiliated_with', 'institution'))\n",
      "    edge_index__author__writes__paper = edge_index.get(('author', 'writes', 'paper'))\n",
      "    edge_index__paper__cites__paper = edge_index.get(('paper', 'cites', 'paper'))\n",
      "    edge_index__paper__has_topic__field_of_study = edge_index.get(('paper', 'has_topic', 'field_of_study'))\n",
      "    edge_index__institution__rev_affiliated_with__author = edge_index.get(('institution', 'rev_affiliated_with', 'author'))\n",
      "    edge_index__paper__rev_writes__author = edge_index.get(('paper', 'rev_writes', 'author'))\n",
      "    edge_index__field_of_study__rev_has_topic__paper = edge_index.get(('field_of_study', 'rev_has_topic', 'paper'));  edge_index = None\n",
      "    convs_0__institution = getattr(self.convs, \"0\").author__affiliated_with__institution((x__author, x__institution), edge_index__author__affiliated_with__institution)\n",
      "    convs_0__paper1 = getattr(self.convs, \"0\").author__writes__paper((x__author, x__paper), edge_index__author__writes__paper)\n",
      "    convs_0__paper2 = getattr(self.convs, \"0\").paper__cites__paper((x__paper, x__paper), edge_index__paper__cites__paper)\n",
      "    convs_0__field_of_study = getattr(self.convs, \"0\").paper__has_topic__field_of_study((x__paper, x__field_of_study), edge_index__paper__has_topic__field_of_study)\n",
      "    convs_0__author1 = getattr(self.convs, \"0\").institution__rev_affiliated_with__author((x__institution, x__author), edge_index__institution__rev_affiliated_with__author)\n",
      "    convs_0__author2 = getattr(self.convs, \"0\").paper__rev_writes__author((x__paper, x__author), edge_index__paper__rev_writes__author)\n",
      "    convs_0__paper3 = getattr(self.convs, \"0\").field_of_study__rev_has_topic__paper((x__field_of_study, x__paper), edge_index__field_of_study__rev_has_topic__paper)\n",
      "    convs_0__paper4 = torch.add(convs_0__paper1, convs_0__paper2);  convs_0__paper1 = convs_0__paper2 = None\n",
      "    convs_0__paper = torch.add(convs_0__paper3, convs_0__paper4);  convs_0__paper3 = convs_0__paper4 = None\n",
      "    convs_0__author = torch.add(convs_0__author1, convs_0__author2);  convs_0__author1 = convs_0__author2 = None\n",
      "    lins_0__paper = getattr(self.lins, \"0\").paper(x__paper);  x__paper = None\n",
      "    lins_0__author = getattr(self.lins, \"0\").author(x__author);  x__author = None\n",
      "    lins_0__institution = getattr(self.lins, \"0\").institution(x__institution);  x__institution = None\n",
      "    lins_0__field_of_study = getattr(self.lins, \"0\").field_of_study(x__field_of_study);  x__field_of_study = None\n",
      "    add_1__paper = convs_0__paper + lins_0__paper;  convs_0__paper = lins_0__paper = None\n",
      "    add_1__author = convs_0__author + lins_0__author;  convs_0__author = lins_0__author = None\n",
      "    add_1__institution = convs_0__institution + lins_0__institution;  convs_0__institution = lins_0__institution = None\n",
      "    add_1__field_of_study = convs_0__field_of_study + lins_0__field_of_study;  convs_0__field_of_study = lins_0__field_of_study = None\n",
      "    bns_0__paper = getattr(self.bns, \"0\").paper(add_1__paper);  add_1__paper = None\n",
      "    bns_0__author = getattr(self.bns, \"0\").author(add_1__author);  add_1__author = None\n",
      "    bns_0__institution = getattr(self.bns, \"0\").institution(add_1__institution);  add_1__institution = None\n",
      "    bns_0__field_of_study = getattr(self.bns, \"0\").field_of_study(add_1__field_of_study);  add_1__field_of_study = None\n",
      "    relu_1__paper = torch.nn.functional.relu(bns_0__paper, inplace = False);  bns_0__paper = None\n",
      "    relu_1__author = torch.nn.functional.relu(bns_0__author, inplace = False);  bns_0__author = None\n",
      "    relu_1__institution = torch.nn.functional.relu(bns_0__institution, inplace = False);  bns_0__institution = None\n",
      "    relu_1__field_of_study = torch.nn.functional.relu(bns_0__field_of_study, inplace = False);  bns_0__field_of_study = None\n",
      "    dropout_1__paper = torch.nn.functional.dropout(relu_1__paper, p = 0.5, training = True, inplace = False);  relu_1__paper = None\n",
      "    dropout_1__author = torch.nn.functional.dropout(relu_1__author, p = 0.5, training = True, inplace = False);  relu_1__author = None\n",
      "    dropout_1__institution = torch.nn.functional.dropout(relu_1__institution, p = 0.5, training = True, inplace = False);  relu_1__institution = None\n",
      "    dropout_1__field_of_study = torch.nn.functional.dropout(relu_1__field_of_study, p = 0.5, training = True, inplace = False);  relu_1__field_of_study = None\n",
      "    convs_1__institution = getattr(self.convs, \"1\").author__affiliated_with__institution((dropout_1__author, dropout_1__institution), edge_index__author__affiliated_with__institution);  edge_index__author__affiliated_with__institution = None\n",
      "    convs_1__paper1 = getattr(self.convs, \"1\").author__writes__paper((dropout_1__author, dropout_1__paper), edge_index__author__writes__paper);  edge_index__author__writes__paper = None\n",
      "    convs_1__paper2 = getattr(self.convs, \"1\").paper__cites__paper((dropout_1__paper, dropout_1__paper), edge_index__paper__cites__paper);  edge_index__paper__cites__paper = None\n",
      "    convs_1__field_of_study = getattr(self.convs, \"1\").paper__has_topic__field_of_study((dropout_1__paper, dropout_1__field_of_study), edge_index__paper__has_topic__field_of_study);  edge_index__paper__has_topic__field_of_study = None\n",
      "    convs_1__author1 = getattr(self.convs, \"1\").institution__rev_affiliated_with__author((dropout_1__institution, dropout_1__author), edge_index__institution__rev_affiliated_with__author);  edge_index__institution__rev_affiliated_with__author = None\n",
      "    convs_1__author2 = getattr(self.convs, \"1\").paper__rev_writes__author((dropout_1__paper, dropout_1__author), edge_index__paper__rev_writes__author);  edge_index__paper__rev_writes__author = None\n",
      "    convs_1__paper3 = getattr(self.convs, \"1\").field_of_study__rev_has_topic__paper((dropout_1__field_of_study, dropout_1__paper), edge_index__field_of_study__rev_has_topic__paper);  edge_index__field_of_study__rev_has_topic__paper = None\n",
      "    convs_1__paper4 = torch.add(convs_1__paper1, convs_1__paper2);  convs_1__paper1 = convs_1__paper2 = None\n",
      "    convs_1__paper = torch.add(convs_1__paper3, convs_1__paper4);  convs_1__paper3 = convs_1__paper4 = None\n",
      "    convs_1__author = torch.add(convs_1__author1, convs_1__author2);  convs_1__author1 = convs_1__author2 = None\n",
      "    lins_1__paper = getattr(self.lins, \"1\").paper(dropout_1__paper);  dropout_1__paper = None\n",
      "    lins_1__author = getattr(self.lins, \"1\").author(dropout_1__author);  dropout_1__author = None\n",
      "    lins_1__institution = getattr(self.lins, \"1\").institution(dropout_1__institution);  dropout_1__institution = None\n",
      "    lins_1__field_of_study = getattr(self.lins, \"1\").field_of_study(dropout_1__field_of_study);  dropout_1__field_of_study = None\n",
      "    add_2__paper = convs_1__paper + lins_1__paper;  convs_1__paper = lins_1__paper = None\n",
      "    add_2__author = convs_1__author + lins_1__author;  convs_1__author = lins_1__author = None\n",
      "    add_2__institution = convs_1__institution + lins_1__institution;  convs_1__institution = lins_1__institution = None\n",
      "    add_2__field_of_study = convs_1__field_of_study + lins_1__field_of_study;  convs_1__field_of_study = lins_1__field_of_study = None\n",
      "    bns_1__paper = getattr(self.bns, \"1\").paper(add_2__paper);  add_2__paper = None\n",
      "    bns_1__author = getattr(self.bns, \"1\").author(add_2__author);  add_2__author = None\n",
      "    bns_1__institution = getattr(self.bns, \"1\").institution(add_2__institution);  add_2__institution = None\n",
      "    bns_1__field_of_study = getattr(self.bns, \"1\").field_of_study(add_2__field_of_study);  add_2__field_of_study = None\n",
      "    relu_2__paper = torch.nn.functional.relu(bns_1__paper, inplace = False);  bns_1__paper = None\n",
      "    relu_2__author = torch.nn.functional.relu(bns_1__author, inplace = False);  bns_1__author = None\n",
      "    relu_2__institution = torch.nn.functional.relu(bns_1__institution, inplace = False);  bns_1__institution = None\n",
      "    relu_2__field_of_study = torch.nn.functional.relu(bns_1__field_of_study, inplace = False);  bns_1__field_of_study = None\n",
      "    dropout_2__paper = torch.nn.functional.dropout(relu_2__paper, p = 0.5, training = True, inplace = False);  relu_2__paper = None\n",
      "    dropout_2__author = torch.nn.functional.dropout(relu_2__author, p = 0.5, training = True, inplace = False);  relu_2__author = None\n",
      "    dropout_2__institution = torch.nn.functional.dropout(relu_2__institution, p = 0.5, training = True, inplace = False);  relu_2__institution = None\n",
      "    dropout_2__field_of_study = torch.nn.functional.dropout(relu_2__field_of_study, p = 0.5, training = True, inplace = False);  relu_2__field_of_study = None\n",
      "    fc_out__paper = self.fc_out.paper(dropout_2__paper);  dropout_2__paper = None\n",
      "    fc_out__author = self.fc_out.author(dropout_2__author);  dropout_2__author = None\n",
      "    fc_out__institution = self.fc_out.institution(dropout_2__institution);  dropout_2__institution = None\n",
      "    fc_out__field_of_study = self.fc_out.field_of_study(dropout_2__field_of_study);  dropout_2__field_of_study = None\n",
      "    return {'paper': fc_out__paper, 'author': fc_out__author, 'institution': fc_out__institution, 'field_of_study': fc_out__field_of_study}\n",
      "    \n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "model2 = Net2(hidden_dim=64, num_classes=dataset.num_classes, num_layers=2)\n",
    "model2.to(device)\n",
    "print(model2)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Net2(\n",
      "  (convs): ModuleList(\n",
      "    (0): HeteroConv(num_relations=7)\n",
      "    (1): HeteroConv(num_relations=7)\n",
      "  )\n",
      "  (bns): ModuleList()\n",
      "  (fc_out): Linear(-1, 349, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "model2.convs[0]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "HeteroConv(num_relations=7)"
      ]
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "@torch.no_grad()\n",
    "def init_params():\n",
    "    # Initialize lazy parameters via forwarding a single batch to the model:\n",
    "    batch = next(iter(train_loader))\n",
    "    batch = batch.to(device)\n",
    "    model(batch.x_dict, batch.edge_index_dict)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    tot_loss = 0\n",
    "    tot_correct"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.11 64-bit ('env_pyg2': conda)"
  },
  "interpreter": {
   "hash": "34c1a40bc9577173535f253d85c3cd5337da8e700227898ef43eef37da3945ea"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}