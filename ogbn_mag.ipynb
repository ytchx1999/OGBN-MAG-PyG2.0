{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "import torch_geometric\n",
    "import torch\n",
    "from torch_geometric.datasets import OGB_MAG\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.loader import NeighborLoader"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "torch.__version__"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'1.7.1'"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "torch_geometric.__version__"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'2.0.1'"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "dataset = OGB_MAG(root='./data', preprocess='transe', transform=T.ToUndirected(merge=True))\n",
    "data = dataset[0]\n",
    "print(data)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Using existing file mag_transe_emb.zip\n",
      "Extracting data/mag/raw/mag_transe_emb.zip\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "HeteroData(\n",
      "  \u001b[1mpaper\u001b[0m={\n",
      "    x=[736389, 128],\n",
      "    y=[736389],\n",
      "    train_mask=[736389],\n",
      "    val_mask=[736389],\n",
      "    test_mask=[736389]\n",
      "  },\n",
      "  \u001b[1mauthor\u001b[0m={ x=[1134649, 256] },\n",
      "  \u001b[1mfield_of_study\u001b[0m={ x=[59965, 256] },\n",
      "  \u001b[1minstitution\u001b[0m={ x=[8740, 256] },\n",
      "  \u001b[1m(author, affiliated_with, institution)\u001b[0m={ edge_index=[2, 1043998] },\n",
      "  \u001b[1m(author, writes, paper)\u001b[0m={ edge_index=[2, 7145660] },\n",
      "  \u001b[1m(paper, cites, paper)\u001b[0m={ edge_index=[2, 10792672] },\n",
      "  \u001b[1m(paper, has_topic, field_of_study)\u001b[0m={ edge_index=[2, 7505078] },\n",
      "  \u001b[1m(institution, rev_affiliated_with, author)\u001b[0m={ edge_index=[2, 1043998] },\n",
      "  \u001b[1m(paper, rev_writes, author)\u001b[0m={ edge_index=[2, 7145660] },\n",
      "  \u001b[1m(field_of_study, rev_has_topic, paper)\u001b[0m={ edge_index=[2, 7505078] }\n",
      ")\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "data.metadata()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(['paper', 'author', 'field_of_study', 'institution'],\n",
       " [('author', 'affiliated_with', 'institution'),\n",
       "  ('author', 'writes', 'paper'),\n",
       "  ('paper', 'cites', 'paper'),\n",
       "  ('paper', 'has_topic', 'field_of_study'),\n",
       "  ('institution', 'rev_affiliated_with', 'author'),\n",
       "  ('paper', 'rev_writes', 'author'),\n",
       "  ('field_of_study', 'rev_has_topic', 'paper')])"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "data.x_dict"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'paper': tensor([[-0.0954,  0.0408, -0.2109,  ...,  0.0616, -0.0277, -0.1338],\n",
       "         [-0.1510, -0.1073, -0.2220,  ...,  0.3458, -0.0277, -0.2185],\n",
       "         [-0.1148, -0.1760, -0.2606,  ...,  0.1731, -0.1564, -0.2780],\n",
       "         ...,\n",
       "         [ 0.0228, -0.0865,  0.0981,  ..., -0.0547, -0.2077, -0.2305],\n",
       "         [-0.2891, -0.2029, -0.1525,  ...,  0.1042,  0.2041, -0.3528],\n",
       "         [-0.0890, -0.0348, -0.2642,  ...,  0.2601, -0.0875, -0.5171]]),\n",
       " 'author': tensor([[ 0.3226,  0.0584, -0.3172,  ..., -0.1393,  0.3022, -0.8178],\n",
       "         [ 0.0438, -0.1213,  0.1804,  ..., -0.3374,  0.4846, -0.4272],\n",
       "         [-0.2300, -0.3192,  0.1979,  ..., -0.1007,  1.3342, -0.4569],\n",
       "         ...,\n",
       "         [-0.5160,  0.1867,  0.2854,  ..., -0.1987, -0.6515,  0.5417],\n",
       "         [-0.3726, -0.1563, -0.1685,  ...,  0.1218,  0.4354, -0.0998],\n",
       "         [-0.7412,  0.5156,  0.0240,  ..., -0.2002, -0.2625, -0.1643]]),\n",
       " 'field_of_study': tensor([[-0.5958,  0.4260,  0.0320,  ..., -0.2224,  0.2888, -0.3681],\n",
       "         [-0.6097,  0.6163, -0.3129,  ..., -0.2189,  0.5175, -0.1438],\n",
       "         [-1.5648, -0.4547, -0.3500,  ..., -0.5007,  0.2203,  0.2191],\n",
       "         ...,\n",
       "         [-0.6005,  0.1640, -0.3107,  ...,  0.1179, -0.3564,  0.1598],\n",
       "         [-0.2118, -0.3852, -0.3192,  ..., -0.3364, -0.0273,  0.7379],\n",
       "         [-0.1771, -0.3896,  0.1770,  ..., -0.1992,  0.1229,  0.2102]]),\n",
       " 'institution': tensor([[-0.1635, -0.1567, -0.0987,  ..., -0.3045, -0.4584,  0.7168],\n",
       "         [ 0.0821, -0.3296, -0.8362,  ...,  0.3981, -0.1279,  0.0892],\n",
       "         [-0.1024, -0.8186, -0.5991,  ..., -0.2871, -0.3805,  0.1945],\n",
       "         ...,\n",
       "         [ 0.6412, -0.1199, -0.6396,  ...,  0.3051, -0.7531,  0.1468],\n",
       "         [ 0.4917,  0.2029, -0.8117,  ...,  1.3380, -0.4822,  0.4772],\n",
       "         [ 0.1683, -0.2391, -0.7174,  ...,  0.3258,  0.0738,  0.7816]])}"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "data.edge_index_dict"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{('author',\n",
       "  'affiliated_with',\n",
       "  'institution'): tensor([[      0,       1,       2,  ..., 1134645, 1134647, 1134648],\n",
       "         [    845,     996,    3197,  ...,    5189,    4668,    4668]]),\n",
       " ('author',\n",
       "  'writes',\n",
       "  'paper'): tensor([[      0,       0,       0,  ..., 1134647, 1134648, 1134648],\n",
       "         [  19703,  289285,  311768,  ...,  657395,  671118,  719594]]),\n",
       " ('paper',\n",
       "  'cites',\n",
       "  'paper'): tensor([[     0,      0,      0,  ..., 736388, 736388, 736388],\n",
       "         [    88,  27449, 121051,  ..., 707740, 732008, 732389]]),\n",
       " ('paper',\n",
       "  'has_topic',\n",
       "  'field_of_study'): tensor([[     0,      0,      0,  ..., 736388, 736388, 736388],\n",
       "         [   145,   2215,   3205,  ...,  21458,  22283,  31934]]),\n",
       " ('institution',\n",
       "  'rev_affiliated_with',\n",
       "  'author'): tensor([[    845,     996,    3197,  ...,    5189,    4668,    4668],\n",
       "         [      0,       1,       2,  ..., 1134645, 1134647, 1134648]]),\n",
       " ('paper',\n",
       "  'rev_writes',\n",
       "  'author'): tensor([[  19703,  289285,  311768,  ...,  657395,  671118,  719594],\n",
       "         [      0,       0,       0,  ..., 1134647, 1134648, 1134648]]),\n",
       " ('field_of_study',\n",
       "  'rev_has_topic',\n",
       "  'paper'): tensor([[   145,   2215,   3205,  ...,  21458,  22283,  31934],\n",
       "         [     0,      0,      0,  ..., 736388, 736388, 736388]])}"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "train_loader = NeighborLoader(data, num_neighbors=[15, 15], batch_size=128, input_nodes=('paper', data['paper'].train_mask), shuffle=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "print(train_loader)\n",
    "batch = next(iter(train_loader))\n",
    "print(batch)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "NeighborLoader()\n",
      "HeteroData(\n",
      "  \u001b[1mpaper\u001b[0m={\n",
      "    x=[23472, 128],\n",
      "    y=[23472],\n",
      "    train_mask=[23472],\n",
      "    val_mask=[23472],\n",
      "    test_mask=[23472],\n",
      "    batch_size=128\n",
      "  },\n",
      "  \u001b[1mauthor\u001b[0m={ x=[4564, 256] },\n",
      "  \u001b[1mfield_of_study\u001b[0m={ x=[2992, 256] },\n",
      "  \u001b[1minstitution\u001b[0m={ x=[345, 256] },\n",
      "  \u001b[1m(author, affiliated_with, institution)\u001b[0m={ edge_index=[2, 0] },\n",
      "  \u001b[1m(author, writes, paper)\u001b[0m={ edge_index=[2, 6007] },\n",
      "  \u001b[1m(paper, cites, paper)\u001b[0m={ edge_index=[2, 13508] },\n",
      "  \u001b[1m(paper, has_topic, field_of_study)\u001b[0m={ edge_index=[2, 11326] },\n",
      "  \u001b[1m(institution, rev_affiliated_with, author)\u001b[0m={ edge_index=[2, 845] },\n",
      "  \u001b[1m(paper, rev_writes, author)\u001b[0m={ edge_index=[2, 5145] },\n",
      "  \u001b[1m(field_of_study, rev_has_topic, paper)\u001b[0m={ edge_index=[2, 11970] }\n",
      ")\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "from torch_geometric.nn import TransformerConv, GCNConv, GATConv, SAGEConv, to_hetero\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "class Net1(torch.nn.Module):\n",
    "    def __init__(self, hidden_dim, num_classes, num_layers=2) -> None:\n",
    "        super(Net1, self).__init__()\n",
    "\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_classes = num_classes\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.convs = nn.ModuleList()\n",
    "        self.lins = nn.ModuleList()\n",
    "        self.bns = nn.ModuleList()\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            self.convs.append(GATConv((-1, -1), hidden_dim))\n",
    "            self.lins.append(nn.Linear(hidden_dim))\n",
    "            self.bns.append(nn.BatchNorm1d(hidden_dim))\n",
    "\n",
    "        # self.dropout = torch.nn.Dropout()\n",
    "        self.fc_out = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.convs[i](x, edge_index) + self.lins[i](x)\n",
    "            x = self.bns[i](x)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.fc_out(x)\n",
    "        return x"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "model = Net1(hidden_dim=64, num_classes=dataset.num_classes, num_layers=2)\n",
    "model = to_hetero(model, data.metadata(), aggr='sum').to(device)\n",
    "print(model)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cuda\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "module 'torch.nn.parameter' has no attribute 'UninitializedParameter'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1557906/3433122585.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNet1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_hetero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maggr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sum'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1557906/1975980647.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, hidden_dim, num_classes, num_layers)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGATConv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBatchNorm1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/env_pyg/lib/python3.7/site-packages/torch_geometric/nn/conv/gat_conv.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_channels, out_channels, heads, concat, negative_slope, dropout, add_self_loops, bias, **kwargs)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             self.lin_src = Linear(in_channels[0], heads * out_channels, False,\n\u001b[0;32m---> 86\u001b[0;31m                                   weight_initializer='glorot')\n\u001b[0m\u001b[1;32m     87\u001b[0m             self.lin_dst = Linear(in_channels[1], heads * out_channels, False,\n\u001b[1;32m     88\u001b[0m                                   weight_initializer='glorot')\n",
      "\u001b[0;32m~/anaconda3/envs/env_pyg/lib/python3.7/site-packages/torch_geometric/nn/dense/linear.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_channels, out_channels, bias, weight_initializer, bias_initializer)\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_channels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUninitializedParameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m             self._hook = self.register_forward_pre_hook(\n\u001b[1;32m     54\u001b[0m                 self.initialize_parameters)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch.nn.parameter' has no attribute 'UninitializedParameter'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "@torch.no_grad()\n",
    "def init_params():\n",
    "    # Initialize lazy parameters via forwarding a single batch to the model:\n",
    "    batch = next(iter(train_loader))\n",
    "    batch = batch.to(device)\n",
    "    model(batch.x_dict, batch.edge_index_dict)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import torch"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "emb = torch.load('./data/mag/raw/mag_metapath2vec_emb.pt', map_location='cpu')\n",
    "emb['paper'].shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([736389, 128])"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "emb['author'].shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([1134649, 128])"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "d1 = {'1': torch.rand((2, 3)), '2': torch.rand((4, 3))}\n",
    "d2 = {'1': torch.rand((2, 3)), '2': torch.rand((4, 3))}\n",
    "{key: x + d2[key] for key, x in d1.items()}"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'1': tensor([[1.8597, 0.6279, 1.0817],\n",
       "         [0.5914, 0.7982, 0.2904]]),\n",
       " '2': tensor([[0.7516, 1.5576, 1.0026],\n",
       "         [0.9337, 1.3418, 1.0792],\n",
       "         [0.8797, 0.9528, 0.7635],\n",
       "         [1.3031, 0.7651, 1.3356]])}"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.11 64-bit ('env_pyg': conda)"
  },
  "interpreter": {
   "hash": "0b363a10e6900ae8f1fd3b5980da931d5b627720339c08a061a0b7390e384b21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}